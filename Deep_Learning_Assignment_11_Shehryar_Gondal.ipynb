{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e6f7ad",
   "metadata": {},
   "source": [
    "__Q1) Write with this : What are the objectives of using Selective Search in R-CNN?__\n",
    "\n",
    "__Answer:__ The objectives of using Selective Search in R-CNN are to generate region proposals in an image to reduce the number of potential object regions that the model needs to process, thereby improving computational efficiency in object detection.\n",
    "\n",
    "__Q2) Explain the following phases involved in R-CNN:__\n",
    "\n",
    "a. Region Proposal<br>\n",
    "b. Region-based CNN (RCNN) <br>\n",
    "c. Region-wise SVM Classifier<br>\n",
    "d. Cleanup <br>\n",
    "e. Implementation of Counting Logic <br>\n",
    "\n",
    "__Q3) What are the possible pre-trained CNNs we can use in the Pre-trained CNN architecture in Fast R-CNN?__\n",
    "\n",
    "__Answer:__ Common pre-trained CNN architectures used in Fast R-CNN include ResNet and VGG for feature extraction.\n",
    "\n",
    "__Q4) How is SVM implemented in the R-CNN framework?__\n",
    "\n",
    "__Answer:__ In the R-CNN framework, Support Vector Machines (SVMs) are used to classify objects within the generated region proposals. SVMs are trained to distinguish between object and non-object regions based on features extracted from these proposals.\n",
    "\n",
    "__Q5) How does Non-Maximum Suppression work in Fast R-CNN?__\n",
    "\n",
    "__Answer:__ Non-Maximum Suppression is a post-processing step used to remove duplicate or highly overlapping region proposals, keeping only the most confident one. It ensures that the model does not detect the same object multiple times.\n",
    "\n",
    "__Q6) How is Fast R-CNN better than R-CNN?__\n",
    "\n",
    "__Answer:__ Fast R-CNN is more efficient than R-CNN as it combines the region proposal generation and feature extraction into a single network. This reduces computational complexity and speeds up the object detection process.\n",
    "\n",
    "__Q7) Using mathematical intuition, explain R^2 pooling in Fast R-CNN.__\n",
    "\n",
    "__Answer:__ R^2 pooling in Fast R-CNN involves dividing the region proposals into a grid and then extracting features from these grid cells. The grid cells correspond to regions of interest (ROIs), and R^2 pooling helps align the features correctly with the ROIs, maintaining their spatial relationships.\n",
    "\n",
    "__Q8) Explain the following processes:__\n",
    "\n",
    "a. ROI Projection<br>\n",
    "b. ROI Pooling <br>\n",
    "\n",
    "__Q9) In comparison with R-CNN, why did the object classifier activation function change in Fast R-CNN?__\n",
    "\n",
    "__Answer:__ In Fast R-CNN, the activation function changed to softmax, allowing the model to produce class probabilities for each object category within a region proposal. This is more appropriate for object classification compared to the SVM used in R-CNN.\n",
    "\n",
    "__Q10) What major changes in Faster R-CNN compared to Fast R-CNN?__\n",
    "\n",
    "__Answer:__ Faster R-CNN introduces a Region Proposal Network (RPN) that is integrated with the CNN architecture, making it more efficient. It replaces the selective search used in Fast R-CNN for generating region proposals.\n",
    "\n",
    "__Q11) Explain the concept of Anchor Boxes.__\n",
    "\n",
    "__Answer:__ Anchor boxes are predefined bounding box shapes with different aspect ratios and scales. They are used in object detection models like Faster R-CNN to help the model predict accurate bounding box coordinates for objects of varying sizes and shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d55d04",
   "metadata": {},
   "source": [
    "__Q12)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ab3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "\n",
    "# Define custom dataset class for COCO dataset\n",
    "class CustomCOCODataset(CocoDetection):\n",
    "    def __init__(self, root, annFile, transforms=None):\n",
    "        super(CustomCOCODataset, self).__init__(root, annFile)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, target = super(CustomCOCODataset, self).__getitem__(idx)\n",
    "        if self.transforms is not None:\n",
    "            image, target = self.transforms(image, target)\n",
    "        return image, target\n",
    "\n",
    "# Define transformations\n",
    "transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "# Initialize COCO dataset\n",
    "dataset = CustomCOCODataset(root='path_to_coco_data', annFile='path_to_annotations', transforms=transform)\n",
    "\n",
    "# Split dataset into training, validation, and test sets\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=utils.collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=utils.collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=utils.collate_fn)\n",
    "\n",
    "# Define Faster R-CNN model with pre-trained ResNet backbone\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Validation loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, targets in val_loader:\n",
    "        predictions = model(images)\n",
    "        # Evaluate and record validation metrics\n",
    "\n",
    "# Inference on test data\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images, targets in test_loader:\n",
    "        predictions.append(model(images))\n",
    "# Process predictions as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
